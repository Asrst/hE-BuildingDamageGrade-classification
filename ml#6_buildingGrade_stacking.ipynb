{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib as mlt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearn\n",
      "  Downloading https://files.pythonhosted.org/packages/81/a7/4179e6ebfd654bd0eac0b9c06125b8b4c96a9d0a8ff9e9507eb2a26d2d7e/imblearn-0.0-py2.py3-none-any.whl\n",
      "Collecting imbalanced-learn (from imblearn)\n",
      "  Downloading https://files.pythonhosted.org/packages/80/a4/900463a3c0af082aed9c5a43f4ec317a9469710c5ef80496c9abc26ed0ca/imbalanced_learn-0.3.3-py3-none-any.whl (144kB)\n",
      "\u001b[K    100% |████████████████████████████████| 153kB 1.3MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/usr/anaconda3/lib/python3.6/site-packages (from imbalanced-learn->imblearn)\n",
      "Requirement already satisfied: scikit-learn in /opt/usr/anaconda3/lib/python3.6/site-packages (from imbalanced-learn->imblearn)\n",
      "Requirement already satisfied: scipy in /opt/usr/anaconda3/lib/python3.6/site-packages (from imbalanced-learn->imblearn)\n",
      "Installing collected packages: imbalanced-learn, imblearn\n",
      "\u001b[31mException:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/usr/anaconda3/lib/python3.6/site-packages/pip/basecommand.py\", line 215, in main\n",
      "    status = self.run(options, args)\n",
      "  File \"/opt/usr/anaconda3/lib/python3.6/site-packages/pip/commands/install.py\", line 342, in run\n",
      "    prefix=options.prefix_path,\n",
      "  File \"/opt/usr/anaconda3/lib/python3.6/site-packages/pip/req/req_set.py\", line 784, in install\n",
      "    **kwargs\n",
      "  File \"/opt/usr/anaconda3/lib/python3.6/site-packages/pip/req/req_install.py\", line 851, in install\n",
      "    self.move_wheel_files(self.source_dir, root=root, prefix=prefix)\n",
      "  File \"/opt/usr/anaconda3/lib/python3.6/site-packages/pip/req/req_install.py\", line 1064, in move_wheel_files\n",
      "    isolated=self.isolated,\n",
      "  File \"/opt/usr/anaconda3/lib/python3.6/site-packages/pip/wheel.py\", line 345, in move_wheel_files\n",
      "    clobber(source, lib_dir, True)\n",
      "  File \"/opt/usr/anaconda3/lib/python3.6/site-packages/pip/wheel.py\", line 316, in clobber\n",
      "    ensure_dir(destdir)\n",
      "  File \"/opt/usr/anaconda3/lib/python3.6/site-packages/pip/utils/__init__.py\", line 83, in ensure_dir\n",
      "    os.makedirs(path)\n",
      "  File \"/opt/usr/anaconda3/lib/python3.6/os.py\", line 220, in makedirs\n",
      "    mkdir(name, mode)\n",
      "PermissionError: [Errno 13] Permission denied: '/opt/usr/anaconda3/lib/python3.6/site-packages/imbalanced_learn-0.3.3.dist-info'\u001b[0m\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 18.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "os.getcwd()\n",
    "!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "itrain = pd.read_csv('/home/sa05975666/Asr/train_set.csv')\n",
    "itest = pd.read_csv('/home/sa05975666/Asr/test_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>age_building</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>188</th>\n",
       "      <th>190</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>199</th>\n",
       "      <th>200</th>\n",
       "      <th>999</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>damage_grade</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Grade 1</th>\n",
       "      <td>1847.0</td>\n",
       "      <td>4548.0</td>\n",
       "      <td>3788.0</td>\n",
       "      <td>4018.0</td>\n",
       "      <td>3548.0</td>\n",
       "      <td>4243.0</td>\n",
       "      <td>2534.0</td>\n",
       "      <td>2677.0</td>\n",
       "      <td>2760.0</td>\n",
       "      <td>1366.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>449.0</td>\n",
       "      <td>61320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Grade 2</th>\n",
       "      <td>166.0</td>\n",
       "      <td>1761.0</td>\n",
       "      <td>2660.0</td>\n",
       "      <td>3446.0</td>\n",
       "      <td>3294.0</td>\n",
       "      <td>4116.0</td>\n",
       "      <td>2846.0</td>\n",
       "      <td>3028.0</td>\n",
       "      <td>3163.0</td>\n",
       "      <td>1903.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>590.0</td>\n",
       "      <td>85084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Grade 3</th>\n",
       "      <td>141.0</td>\n",
       "      <td>1499.0</td>\n",
       "      <td>2344.0</td>\n",
       "      <td>2989.0</td>\n",
       "      <td>3107.0</td>\n",
       "      <td>3845.0</td>\n",
       "      <td>2744.0</td>\n",
       "      <td>3333.0</td>\n",
       "      <td>3460.0</td>\n",
       "      <td>2295.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.0</td>\n",
       "      <td>688.0</td>\n",
       "      <td>122288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Grade 4</th>\n",
       "      <td>150.0</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>2226.0</td>\n",
       "      <td>2756.0</td>\n",
       "      <td>2908.0</td>\n",
       "      <td>3533.0</td>\n",
       "      <td>2729.0</td>\n",
       "      <td>3395.0</td>\n",
       "      <td>3400.0</td>\n",
       "      <td>2391.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>682.0</td>\n",
       "      <td>152244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Grade 5</th>\n",
       "      <td>767.0</td>\n",
       "      <td>3006.0</td>\n",
       "      <td>3371.0</td>\n",
       "      <td>3870.0</td>\n",
       "      <td>3817.0</td>\n",
       "      <td>5257.0</td>\n",
       "      <td>3761.0</td>\n",
       "      <td>4763.0</td>\n",
       "      <td>4659.0</td>\n",
       "      <td>3409.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.0</td>\n",
       "      <td>892.0</td>\n",
       "      <td>210825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>3071.0</td>\n",
       "      <td>12322.0</td>\n",
       "      <td>14389.0</td>\n",
       "      <td>17079.0</td>\n",
       "      <td>16674.0</td>\n",
       "      <td>20994.0</td>\n",
       "      <td>14614.0</td>\n",
       "      <td>17196.0</td>\n",
       "      <td>17442.0</td>\n",
       "      <td>11364.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>3301.0</td>\n",
       "      <td>631761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 179 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "age_building       0        1        2        3        4        5        6  \\\n",
       "damage_grade                                                                 \n",
       "Grade 1       1847.0   4548.0   3788.0   4018.0   3548.0   4243.0   2534.0   \n",
       "Grade 2        166.0   1761.0   2660.0   3446.0   3294.0   4116.0   2846.0   \n",
       "Grade 3        141.0   1499.0   2344.0   2989.0   3107.0   3845.0   2744.0   \n",
       "Grade 4        150.0   1508.0   2226.0   2756.0   2908.0   3533.0   2729.0   \n",
       "Grade 5        767.0   3006.0   3371.0   3870.0   3817.0   5257.0   3761.0   \n",
       "All           3071.0  12322.0  14389.0  17079.0  16674.0  20994.0  14614.0   \n",
       "\n",
       "age_building        7        8        9   ...    188  190  192  193  195  196  \\\n",
       "damage_grade                              ...                                   \n",
       "Grade 1        2677.0   2760.0   1366.0   ...    NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "Grade 2        3028.0   3163.0   1903.0   ...    NaN  1.0  NaN  NaN  NaN  NaN   \n",
       "Grade 3        3333.0   3460.0   2295.0   ...    NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "Grade 4        3395.0   3400.0   2391.0   ...    1.0  4.0  NaN  1.0  1.0  NaN   \n",
       "Grade 5        4763.0   4659.0   3409.0   ...    NaN  2.0  1.0  NaN  NaN  2.0   \n",
       "All           17196.0  17442.0  11364.0   ...    1.0  7.0  1.0  1.0  1.0  2.0   \n",
       "\n",
       "age_building  199    200     999     All  \n",
       "damage_grade                              \n",
       "Grade 1       NaN    4.0   449.0   61320  \n",
       "Grade 2       1.0   13.0   590.0   85084  \n",
       "Grade 3       NaN   41.0   688.0  122288  \n",
       "Grade 4       2.0   99.0   682.0  152244  \n",
       "Grade 5       NaN   86.0   892.0  210825  \n",
       "All           3.0  243.0  3301.0  631761  \n",
       "\n",
       "[6 rows x 179 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = pd.pivot_table(data = itrain, index = 'damage_grade', columns = 'age_building', values = 'building_id', \n",
    "               aggfunc = 'count', margins = True)\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itrain['delta_countFloors'] = itrain['count_floors_pre_eq'] - itrain['count_floors_post_eq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itrain['delta_Height'] = itrain['height_ft_pre_eq'] - itrain['height_ft_post_eq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itest['delta_countFloors'] = itest['count_floors_pre_eq'] - itest['count_floors_post_eq']\n",
    "itest['delta_Height'] = itest['height_ft_pre_eq'] - itest['height_ft_post_eq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_col = ['count_floors_pre_eq', 'count_floors_post_eq', 'age_building', 'plinth_area_sq_ft', 'height_ft_pre_eq', \n",
    "           'height_ft_post_eq', 'count_families']\n",
    "df = itrain[num_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "df1 =itrain[(np.abs(stats.zscore(df)) < 3).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itrain = df1.copy()\n",
    "print(df1.shape)\n",
    "itrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itrain['damage_grade'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['damage_grade'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(itrain[['ward_id', 'district_id', 'vdcmun_id']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(itest[['ward_id', 'district_id', 'vdcmun_id']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(itrain[num_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(itest[num_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(itrain[num_col].corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(15,10))\n",
    "df1[num_col].boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cr = itrain.corr()\n",
    "#cr>0.7\n",
    "#sns.heatmap(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itrain['damage_grade'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_col = ['plan_configuration_H-shape', 'has_secondary_use_gov_office', 'has_secondary_use_use_police', \n",
    "            'has_secondary_use_health_post', 'plan_configuration_E-shape', 'plan_configuration_Building with Central Courtyard', \n",
    "            'has_secondary_use_school','plan_configuration_U-shape', 'has_secondary_use_institution', \n",
    "            'condition_post_eq_Covered by landslide', 'has_secondary_use_industry', 'plan_configuration_T-shape', \n",
    "            'plan_configuration_Others', 'plan_configuration_Multi-projected', \n",
    "            'has_geotechnical_risk_other','ground_floor_type_Other', 'has_geotechnical_risk_liquefaction',\n",
    "            'area_assesed_Interior', 'position_Attached-3 side', 'condition_post_eq_Damaged-Rubble Clear-New building built', \n",
    "            'legal_ownership_status_Other', 'has_secondary_use_rental', 'plan_configuration_L-shape', \n",
    "            'legal_ownership_status_Institutional', 'building_id', \n",
    "            'has_geotechnical_risk_flood',\n",
    "            'area_assesed_Not able to inspect','plan_configuration_Square',\n",
    " 'has_secondary_use_hotel',\n",
    " 'plan_configuration_Rectangular',\n",
    " 'has_superstructure_cement_mortar_stone',\n",
    " 'foundation_type_Other',\n",
    " 'has_superstructure_rc_engineered',\n",
    " 'position_Attached-2 side',\n",
    " 'legal_ownership_status_Public',\n",
    " 'has_geotechnical_risk_rock_fall',\n",
    " 'has_superstructure_other',\n",
    " 'has_secondary_use_other',\n",
    " 'legal_ownership_status_Private',\n",
    " 'land_surface_condition_Steep slope',\n",
    " 'foundation_type_Cement-Stone/Brick',\n",
    " 'has_geotechnical_risk_fault_crack','count_families','district_id', 'vdcmun_id']\n",
    "\n",
    "# 'has_geotechnical_risk_landslide',\n",
    "#  'position_Attached-1 side',\n",
    "#  'foundation_type_Bamboo/Timber',\n",
    "#  'other_floor_type_RCC/RB/RBC',\n",
    "#  'has_secondary_use_agriculture',\n",
    "#  'ground_floor_type_Timber',\n",
    "#  'has_secondary_use',\n",
    "#  'has_geotechnical_risk_land_settlement',\n",
    "#  'other_floor_type_Not applicable',\n",
    "#  'position_Not attached',\n",
    "#  'land_surface_condition_Moderate slope',\n",
    "#  'has_superstructure_stone_flag',\n",
    "#  'has_superstructure_rc_non_engineered',\n",
    "#  'has_superstructure_mud_mortar_brick',\n",
    "#  'has_superstructure_bamboo',\n",
    "#  'roof_type_Bamboo/Timber-Heavy roof',\n",
    "#  'ground_floor_type_Brick/Stone',\n",
    "#  'has_superstructure_adobe_mud',\n",
    "#  'has_geotechnical_risk',\n",
    "#  'other_floor_type_Timber-Planck',\n",
    "#  'roof_type_Bamboo/Timber-Light roof'\n",
    "# dump_col = ['building_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = itrain.drop(dump_col, axis = 1)\n",
    "predictors = predictors.drop('damage_grade', axis = 1)\n",
    "target = itrain['damage_grade']\n",
    "#target = target.replace({'Grade 1': 1, 'Grade 2': 2, 'Grade 3': 3,'Grade 4': 4,'Grade 5': 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = itest.drop(dump_col, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#col_names\n",
    "print(predictors.shape)\n",
    "test_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target = target.astype(object)\n",
    "# weights\n",
    "{'Grade 1': 3.4381115459882583, 'Grade 2': 2.47784542334634, \n",
    "        'Grade 3': 1.7240039905796154,'Grade 4': 1.3847836367935682,'Grade 5': 1.0}\n",
    "\n",
    "# {'Grade 1': 3.4381115459882583, 'Grade 2': 5.47784542334634, \n",
    "#         'Grade 3': 6.7240039905796154,'Grade 4': 5.3847836367935682,'Grade 5': 1.0}\n",
    "\n",
    "{'Grade 1': 3.4381115459882583, 'Grade 2': 3.47784542334634, \n",
    "        'Grade 3': 2.7240039905796154,'Grade 4': 2.3847836367935682,'Grade 5': 1.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing packages from sk learn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "#FUNCTION for Train & Validation set\n",
    "X_train, X_test, y_train, y_test = train_test_split(predictors, target, train_size=0.7, test_size=0.3, \n",
    "                                                    random_state = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.grid_search import GridSearchCV\n",
    "# random_classifier = RandomForestClassifier()\n",
    "# parameters = { 'max_features':np.arange(5,10),'n_estimators':[500],'min_samples_leaf': [10,50,100,200,500]}\n",
    "# random_grid = GridSearchCV(random_classifier, parameters, cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = RandomForestClassifier(n_estimators = 549, max_features = 25 , min_samples_leaf = 3, min_samples_split = 11,\n",
    "                              n_jobs = -1, class_weight = {'Grade 1': 3.4381115459882583, 'Grade 2': 5.47784542334634, \n",
    "     'Grade 3': 6.7240039905796154,'Grade 4': 5.3847836367935682,'Grade 5': 1.0}, random_state = 7)\n",
    "\n",
    "model1.fit(X_train, y_train)\n",
    "\n",
    "predict_train1 = model1.predict(X_train)\n",
    "predicted_test1 = model1.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predicted_test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#77.3897 for 549,25\n",
    "# 77.40\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "#CM = confusion_matrix(y_test, predicted_val)\n",
    "from sklearn.metrics import f1_score\n",
    "display(f1_score(y_test, predicted_test1, average='weighted'))\n",
    "\n",
    "RfCM = pd.crosstab(y_test, predicted_test1)\n",
    "RfCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model2 = RandomForestClassifier(n_estimators = 549, max_features = 25 , min_samples_leaf = 3, min_samples_split = 11,\n",
    "#                               n_jobs = -1, class_weight = {'Grade 1': 3.4381115459882583, 'Grade 2': 1.47784542334634, \n",
    "#         'Grade 3': 2.7240039905796154,'Grade 4': 25.3847836367935682,'Grade 5': 1.0}, random_state = 7)\n",
    "\n",
    "# model2.fit(X_train, y_train)\n",
    "\n",
    "# predict_train2 = model2.predict(X_train)\n",
    "# predicted_test2 = model2.predict(X_test)\n",
    "\n",
    "# from sklearn.metrics import classification_report\n",
    "# print(classification_report(y_test, predicted_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model3 = RandomForestClassifier(n_estimators = 549, max_features = 25 , min_samples_leaf = 3, min_samples_split = 11,\n",
    "#                               n_jobs = -1, class_weight = {'Grade 1': 3.4381115459882583, 'Grade 2': 15.47784542334634, \n",
    "#         'Grade 3': 1.7240039905796154,'Grade 4': 12.3847836367935682,'Grade 5': 1.0}, random_state = 7)\n",
    "# model3.fit(X_train, y_train)\n",
    "\n",
    "# predict_train3 = model3.predict(X_train)\n",
    "# predicted_test3 = model3.predict(X_test)\n",
    "\n",
    "# from sklearn.metrics import classification_report\n",
    "# print(classification_report(y_test, predicted_test3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = RandomForestClassifier(n_estimators = 549, max_features = 25 , min_samples_leaf = 3, min_samples_split = 11,\n",
    "                              n_jobs = -1, class_weight = {'Grade 1': 3.4381115459882583, \n",
    "                                                                           'Grade 2': 2.47784542334634, \n",
    "                                                                           'Grade 3': 1.7240039905796154,\n",
    "                                                                           'Grade 4': 1.3847836367935682,\n",
    "                                                                           'Grade 5': 1.0},  random_state = 7)\n",
    "\n",
    "model4.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "predict_train4 = model4.predict(X_train)\n",
    "predicted_test4 = model4.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predicted_test4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking models\n",
    "### df = pd.DataFrame(data = {'m1': predict_train1, 'm2': predict_train2, 'm3': predict_train3, 'm4':predict_train4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_train = pd.DataFrame(data = {'m1': predict_train1, 'm4':predict_train4})\n",
    "stack_test = pd.DataFrame(data = {'m1': predicted_test1, 'm4':predicted_test4})\n",
    "\n",
    "# df_train= pd.get_dummies(data = stack_train)\n",
    "# df_test= pd.get_dummies(data = stack_test)\n",
    "\n",
    "df_train = stack_train.replace({'Grade 1': 1, 'Grade 2': 2, 'Grade 3': 3,'Grade 4': 4,'Grade 5': 5})\n",
    "df_test = stack_test.replace({'Grade 1': 1, 'Grade 2': 2, 'Grade 3': 3,'Grade 4': 4,'Grade 5': 5})\n",
    "\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# StacK_classifier = LogisticRegression(C = 0.5, random_state=7, class_weight = 'balanced')\n",
    "# Stack_classifier.fit(df_train, y_train)\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "Stack_model = XGBClassifier(learning_rate =0.1, n_estimators=1000, max_depth=4,\n",
    " min_child_weight=6, gamma=0,subsample=0.8, colsample_bytree=0.8, scale_pos_weight=1, seed=27)\n",
    "\n",
    "Stack_model.fit(df_train, y_train, verbose=False)\n",
    "\n",
    "predicted_stack = Stack_model.predict(df_test)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predicted_stack))\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "display(f1_score(y_test, predicted_stack, average='weighted'))\n",
    "\n",
    "XgCM = pd.crosstab(y_test, predicted_stack)\n",
    "XgCM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Navie Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training a Naive Bayes classifier\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB().fit(df_train, y_train)\n",
    "gnb_predictions = gnb.predict(df_test)\n",
    " \n",
    "# accuracy on X_test\n",
    "accuracy = gnb.score(df_test, y_test)\n",
    "print(accuracy)\n",
    " \n",
    "# creating a confusion matrix\n",
    "NbCM = pd.crosstab(y_test, gnb_predictions)\n",
    "NbCM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # training a KNN classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 11).fit(df_train, y_train)\n",
    " \n",
    "# # accuracy on X_test\n",
    "accuracy = knn.score(df_test, y_test)\n",
    "print(accuracy)\n",
    "\n",
    "# # creating a confusion matrix\n",
    "knn_predictions = knn.predict(df_test) \n",
    "KnnCM = pd.crosstab(y_test, knn_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> features = X_train.columns\n",
    ">>> importances = model1.feature_importances_\n",
    ">>> indices = np.argsort(importances)\n",
    "col_names = []\n",
    "for i in indices:\n",
    "    n = features[i]\n",
    "    col_names.append(n)\n",
    "\n",
    ">>> plt.figure(figsize=(10,15))\n",
    ">>> plt.title('Feature Importances')\n",
    ">>> plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    ">>> plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    ">>> plt.xlabel('Relative Importance')\n",
    ">>> plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Predictions on test data for Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_estimators = 599,max_features = 34,min_samples_leaf = 3,min_samples_split=11,class_weight = 'balanced_subsample'(77.4,74.4)\n",
    "#n=799, 77.25 (All)\n",
    "#n=999, 77.22 \n",
    "#n_estimators = 599, max_features = 43, min_samples_leaf = 5, min_samples_split=16, n_jobs = -1, 77.17\n",
    "#n_estimators = 599, max_features = 34, min_samples_leaf = 7, min_samples_split=25, n_jobs = -1, 77.03 (72 features)\n",
    "# n_estimators = 999, max_features = 34, min_samples_leaf = 7, min_samples_split=16, n_jobs = -1, 77.05 (52 features)\n",
    "# n_estimators = 999, max_features = 25, min_samples_leaf = 3, min_samples_split=11, n_jobs = -1, 77.35 (52)\n",
    "#n_estimators = 999, max_features = 16, min_samples_leaf = 3, min_samples_split=11, n_jobs = -1, 77.24 (32)\n",
    "#n_estimators = 1299, max_features = 16, min_samples_leaf = 3, min_samples_split=13, n_jobs = -1, 77.17 (32)\n",
    "\n",
    "\n",
    "trainModel = RandomForestClassifier(n_estimators = 549, max_features = 25, min_samples_leaf = 3, min_samples_split = 11, \n",
    "                                    n_jobs = -1, class_weight = {'Grade 1': 3.4381115459882583, 'Grade 2': 5.47784542334634, \n",
    "        'Grade 3': 6.7240039905796154,'Grade 4': 5.3847836367935682,'Grade 5': 1.0})\n",
    "trainModel.fit(predictors, target)\n",
    "predictions = trainModel.predict(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = RandomForestClassifier(n_estimators = 549, max_features = 25 , min_samples_leaf = 3, min_samples_split = 11,\n",
    "                              n_jobs = -1, class_weight = {'Grade 1': 3.4381115459882583, 'Grade 2': 5.47784542334634, \n",
    "     'Grade 3': 6.7240039905796154,'Grade 4': 5.3847836367935682,'Grade 5': 1.0}, random_state = 7)\n",
    "\n",
    "model1.fit(predictors, target)\n",
    "\n",
    "predict_train1 = model1.predict(predictors)\n",
    "predicted_test1 = model1.predict(test_set)\n",
    "\n",
    "\n",
    "model4 = RandomForestClassifier(n_estimators = 549, max_features = 25 , min_samples_leaf = 3, min_samples_split = 11,\n",
    "                              n_jobs = -1, class_weight = {'Grade 1': 3.4381115459882583, 'Grade 2': 7.47784542334634, \n",
    "        'Grade 3': 1.7240039905796154,'Grade 4': 5.3847836367935682,'Grade 5': 1.0}, random_state = 7)\n",
    "\n",
    "model4.fit(X_train, y_train)\n",
    "\n",
    "predict_train4 = model4.predict(predictors)\n",
    "predicted_test4 = model4.predict(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_train = pd.DataFrame(data = {'m1': predict_train1, 'm4':predict_train4})\n",
    "stack_test = pd.DataFrame(data = {'m1': predicted_test1, 'm4':predicted_test4})\n",
    "\n",
    "# df_train= pd.get_dummies(data = stack_train)\n",
    "# df_test= pd.get_dummies(data = stack_test)\n",
    "\n",
    "df_train = stack_train.replace({'Grade 1': 1, 'Grade 2': 2, 'Grade 3': 3,'Grade 4': 4,'Grade 5': 5})\n",
    "df_test = stack_test.replace({'Grade 1': 1, 'Grade 2': 2, 'Grade 3': 3,'Grade 4': 4,'Grade 5': 5})\n",
    "\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# StacK_classifier = LogisticRegression(C = 0.5, random_state=7, class_weight = 'balanced')\n",
    "# Stack_classifier.fit(df_train, y_train)\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "Stack_model = XGBClassifier(learning_rate = 0.1, n_estimators=1000, max_depth=8,\n",
    " min_child_weight=6, gamma=0,subsample=0.8, colsample_bytree=0.8, scale_pos_weight=1, seed=27)\n",
    "\n",
    "Stack_model.fit(df_train, target, verbose=False)\n",
    "predicted_stack = Stack_model.predict(df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(itest.building_id)\n",
    "submission['damage_grade'] = predicted_stack\n",
    "submission.to_csv('hE_Ml6_sub05.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #predictions = trainModel.predict(test_set)\n",
    "# predicted_train = trainModel.predict(predictors)\n",
    "# trainCM = pd.crosstab(target, predicted_train)\n",
    "# trainCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
